##
For pretrain the result for SST are as follows (Note the LR):

args: {'train': 'data/sst-train.txt', 'dev': 'data/sst-dev.txt', 'test': 'data/sst-test.txt', 'seed': 1234, 'epochs': 10, 'option': 'pretrain', 'filepath': 'CAMPUSID4/sst-model.pt', 'use_gpu': True, 'dev_out': 'CAMPUSID4/sst-dev-output.txt', 'test_out': 'CAMPUSID4/sst-test-output.txt', 'batch_size': 8, 'hidden_dropout_prob': 0.3, 'lr': 0.001}
load 8544 data from data/sst-train.txt
load 1101 data from data/sst-dev.txt
save the model to CAMPUSID4/sst-model.pt
epoch 0: train loss :: 1.589, train acc :: 0.366, dev acc :: 0.357
epoch 1: train loss :: 1.524, train acc :: 0.365, dev acc :: 0.356
epoch 2: train loss :: 1.515, train acc :: 0.346, dev acc :: 0.345
epoch 3: train loss :: 1.487, train acc :: 0.351, dev acc :: 0.344
save the model to CAMPUSID4/sst-model.pt
epoch 4: train loss :: 1.486, train acc :: 0.371, dev acc :: 0.377
save the model to CAMPUSID4/sst-model.pt
epoch 5: train loss :: 1.475, train acc :: 0.417, dev acc :: 0.387
epoch 6: train loss :: 1.477, train acc :: 0.391, dev acc :: 0.372
save the model to CAMPUSID4/sst-model.pt
epoch 7: train loss :: 1.469, train acc :: 0.405, dev acc :: 0.392
epoch 8: train loss :: 1.475, train acc :: 0.415, dev acc :: 0.382
save the model to CAMPUSID4/sst-model.pt
epoch 9: train loss :: 1.473, train acc :: 0.429, dev acc :: 0.398
load model from CAMPUSID4/sst-model.pt
load 1101 data from data/sst-dev.txt
load 2210 data from data/sst-test.txt
dev acc :: 0.398
test acc :: 0.421

For pretrain the result for CF-IMDB are as follows :

args: {'train': 'data/cfimdb-train.txt', 'dev': 'data/cfimdb-dev.txt', 'test': 'data/cfimdb-test.txt', 'seed': 1234, 'epochs': 10, 'option': 'pretrain', 'filepath': 'CAMPUSID/cfimdb-model.pt', 'use_gpu': True, 'dev_out': 'CAMPUSID/cfimdb-dev-output.txt', 'test_out': 'CAMPUSID/cfimdb-test-output.txt', 'batch_size': 8, 'hidden_dropout_prob': 0.3, 'lr': 1e-05}
load 1707 data from data/cfimdb-train.txt
load 245 data from data/cfimdb-dev.txt
save the model to CAMPUSID/cfimdb-model.pt
epoch 0: train loss :: 0.699, train acc :: 0.521, dev acc :: 0.543
epoch 1: train loss :: 0.696, train acc :: 0.521, dev acc :: 0.531
epoch 2: train loss :: 0.699, train acc :: 0.530, dev acc :: 0.531
epoch 3: train loss :: 0.701, train acc :: 0.529, dev acc :: 0.527
epoch 4: train loss :: 0.695, train acc :: 0.533, dev acc :: 0.527
epoch 5: train loss :: 0.698, train acc :: 0.535, dev acc :: 0.531
save the model to CAMPUSID/cfimdb-model.pt
epoch 6: train loss :: 0.701, train acc :: 0.544, dev acc :: 0.571
epoch 7: train loss :: 0.705, train acc :: 0.537, dev acc :: 0.539
save the model to CAMPUSID/cfimdb-model.pt
epoch 8: train loss :: 0.694, train acc :: 0.551, dev acc :: 0.576
epoch 9: train loss :: 0.698, train acc :: 0.537, dev acc :: 0.555
load model from CAMPUSID/cfimdb-model.pt
load 245 data from data/cfimdb-dev.txt
load 488 data from data/cfimdb-test.txt
dev acc :: 0.576
test acc :: 0.674

Found issues in training cfimdb, as the given GPU limited batch_size to be used 4 during fine tuning.
The assert for optimizer fails by 0.0001, due to mathematical appoximation.

Other this tried to reduce/increase dropout and learning rate, but didn't have significant attempt.
Append the model from assignment 1 in the classfication part, didn't achieve significant results but also couldn't train till completion due to GPU issues.


